# Instalação Data Lake

# Instalando e Configurando o Hadoop

# Acessar via browser (se tiver problema ao conectar, verifique o firewall do servidor:  e pare o serviço assim:
    cmd: service firewalld status
    cmd: service firewalld stop
    cmd: sudo systemctl disable firewalld
# Iniciar o HDFS (trouleshooting do problema com o Java)

    cmd: $HADOOP_HOME/sbin/start-dfs.sh
    cmd: $HADOOP_HOME/sbin/stop-all.sh # para finalizar

# Acesso ao cluster via browser:

http://192.168.15.16:9870
http://192.168.15.16:9864


# Analisar o cluster:

    cmd: hdfs dfsadmin -report


# Iniciar o YARN

    cmd: $HADOOP_HOME/sbin/start-yarn.sh


# Testando o cluster:

wget http://datascienceacademy.com.br/blog/aluno/RFundamentos/Datasets/Parte2/questoes.csv

hdfs dfs -put questoes.csv /datasets
hdfs dfs -mkdir /datasets

hdfs dfs -ls /datasets


# Executando o Job de processamento de MapReduce via YARN (contagem de palavras no arquivo)

yarn jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar wordcount "/datasets/questoes.csv" output


# Checando a execução do Job:

hdfs dfs -cat output/part-r-00000
yarn node -list
yarn application -list


# Acessar via browser:
http://192.168.1.76:8088/cluster


# Parar o cluster:

$HADOOP_HOME/sbin/stop-yarn.sh
$HADOOP_HOME/sbin/stop-dfs.sh

